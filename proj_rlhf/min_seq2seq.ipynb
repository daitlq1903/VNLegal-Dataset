{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DevTools/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(object):\n",
    "    def __init__(self, vocab_size, embedding_size, num_units, num_layers, out_keep_prob, batch_size, encoder_size, decoder_size, start_of_sequence_id, end_of_sequence_id, pad_of_sequence_id, learning_rate=0.0001, use_attention=False):\n",
    "        print('Init new model')\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_units = num_units\n",
    "        self.num_layers = num_layers\n",
    "        self.out_keep_prob = out_keep_prob\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.time_major = True\n",
    "        self.use_attention = use_attention\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.counter = tf.Variable(0, name='counter')\n",
    "        \n",
    "        self.encoder_size = encoder_size\n",
    "        self.decoder_size = decoder_size\n",
    "        self.start_of_sequence_id = start_of_sequence_id\n",
    "        self.end_of_sequence_id = end_of_sequence_id\n",
    "        self.pad_of_sequence_id = pad_of_sequence_id\n",
    "        \n",
    "        \n",
    "    def createCell(self, num_units, num_layers):\n",
    "        #return tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "        cells = []\n",
    "        for _ in range(self.num_layers):\n",
    "            cell = tf.contrib.rnn.LSTMCell(self.num_units)  # Or LSTMCell(num_units)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.out_keep_prob)\n",
    "            cells.append(cell)\n",
    "        stacked_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "        return stacked_cell\n",
    "    \n",
    "    \n",
    "    def build(self):\n",
    "        self._init_placeholders()\n",
    "        self._init_embeddings()\n",
    "        #self._init_encoder()\n",
    "        self._init_bidirectional_encoder()\n",
    "        self._init_decoder()\n",
    "        self._init_optimizer()\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        self.encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "        self.decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "        self.decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "        \n",
    "        self.source_sequence_length = tf.placeholder(tf.int32, (None,), name='source_sequence_length')\n",
    "        self.target_sequence_length = tf.placeholder(tf.int32, (None,), name='target_sequence_length')\n",
    "        \n",
    "        self.max_target_sequence_length = tf.reduce_max(self.target_sequence_length, name='max_target_length')\n",
    "        \n",
    "        \n",
    "    def _init_embeddings(self):\n",
    "        with tf.variable_scope(\"embedding\") as scope:\n",
    "            # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "            sqrt3 = math.sqrt(3)\n",
    "            initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "            \n",
    "            self.embedding_matrix = tf.get_variable(\n",
    "                                        name=\"embedding_matrix\",\n",
    "                                        shape=[self.vocab_size, self.embedding_size],\n",
    "                                        initializer=initializer,\n",
    "                                        dtype=tf.float32\n",
    "                                    )\n",
    "            \n",
    "            self.embeddings = tf.Variable(tf.random_uniform([self.vocab_size, self.embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "            self.encoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.encoder_inputs)\n",
    "            self.decoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.decoder_inputs)\n",
    "            \n",
    "            #self.encoder_inputs_embedded = tf.contrib.layers.embed_sequence(self.encoder_inputs, self.vocab_size, self.embedding_size)\n",
    "            #self.embedding_matrix = tf.Variable(tf.random_uniform([self.vocab_size, self.embedding_size]))\n",
    "            #self.decoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.decoder_inputs)\n",
    "    \n",
    "    \n",
    "    def _init_encoder(self):\n",
    "        with tf.variable_scope(\"encoder\") as scope:\n",
    "            self.encoder_cell = self.createCell(self.num_units, self.num_layers)\n",
    "            self.encoder_outputs, self.encoder_state = tf.nn.dynamic_rnn(\n",
    "                                                                        cell=self.encoder_cell,\n",
    "                                                                        inputs=self.encoder_inputs_embedded,\n",
    "                                                                        dtype=tf.float32,\n",
    "                                                                        sequence_length=self.source_sequence_length,\n",
    "                                                                        time_major=self.time_major\n",
    "                                                                    )\n",
    "    \n",
    "    \n",
    "    def _init_bidirectional_encoder(self):\n",
    "        with tf.variable_scope(\"bidirectional_encoder\") as scope:\n",
    "            num_bi_layers = int(self.num_layers / 2)\n",
    "            self.encoder_cell_fw = self.createCell(self.num_units, num_bi_layers)\n",
    "            self.encoder_cell_bw = self.createCell(self.num_units, num_bi_layers)\n",
    "            \n",
    "            encoder_outputs, bi_encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                                                cell_fw=self.encoder_cell_fw,\n",
    "                                                                cell_bw=self.encoder_cell_bw,\n",
    "                                                                inputs=self.encoder_inputs_embedded,\n",
    "                                                                dtype=tf.float32,\n",
    "                                                                sequence_length=self.source_sequence_length,\n",
    "                                                                time_major=self.time_major,\n",
    "                                                                swap_memory=True\n",
    "                                                            )\n",
    "            #self.encoder_outputs = tf.concat(outputs, -1)\n",
    "            #self.encoder_state = states\n",
    "            #if num_bi_layers == 1:\n",
    "            #    self.encoder_state = bi_encoder_state\n",
    "            #else:\n",
    "            # alternatively concat forward and backward states\n",
    "            self.encoder_state = []\n",
    "            for layer_id in range(num_bi_layers):\n",
    "                self.encoder_state.append(bi_encoder_state[0][layer_id])  # forward\n",
    "                self.encoder_state.append(bi_encoder_state[1][layer_id])  # backward\n",
    "            self.encoder_state = tuple(self.encoder_state)\n",
    "                \n",
    "            self.encoder_outputs = tf.concat(encoder_outputs, -1)\n",
    "            \n",
    "            \n",
    "    def _init_decoder(self):\n",
    "\n",
    "        output_layer = Dense(self.vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "        \n",
    "        with tf.variable_scope(\"decoder\") as scope:\n",
    "            \n",
    "            if self.use_attention:\n",
    "                #attention_states: [batch_size, max_time, num_units] (not time_major)\n",
    "                if self.time_major:\n",
    "                    attention_states = tf.transpose(self.encoder_outputs, [1, 0, 2])\n",
    "                else:\n",
    "                    attention_states = self.encoder_outputs\n",
    "\n",
    "                # Create an attention mechanism\n",
    "                attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "                                    num_units=self.num_units, memory=attention_states,\n",
    "                                    memory_sequence_length=self.source_sequence_length)\n",
    "                \n",
    "                stacked_cell = self.createCell(self.num_units, self.num_layers)\n",
    "                #attention_cell= tf.contrib.rnn.BasicLSTMCell(self.num_units)\n",
    "                attention_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                                                                    cell=stacked_cell,\n",
    "                                                                    attention_mechanism=attention_mechanism,\n",
    "                                                                    attention_layer_size=self.num_units,  # don't add an additional dense layer.\n",
    "                                                                    output_attention=False)\n",
    "                #self.decoder_cell= GNMTAttentionMultiCell(attention_cell, cells)\n",
    "                \n",
    "                self.decoder_cell = attention_cell\n",
    "\n",
    "                initial_state = self.decoder_cell.zero_state(self.batch_size, tf.float32).clone(cell_state=self.encoder_state)\n",
    "                #initial_state = self.decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
    "            else:\n",
    "                self.decoder_cell = self.createCell(self.num_units, self.num_layers)\n",
    "                initial_state =self.encoder_state\n",
    "            \n",
    "            # Helper for the training process. Used by BasicDecoder to read inputs.\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=self.decoder_inputs_embedded,\n",
    "                                                                sequence_length=self.target_sequence_length,\n",
    "                                                                time_major=self.time_major)\n",
    "\n",
    "\n",
    "            # Basic decoder\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=self.decoder_cell,\n",
    "                                                               helper=training_helper,\n",
    "                                                               initial_state=initial_state,\n",
    "                                                               output_layer=output_layer) \n",
    "\n",
    "            # Perform dynamic decoding using the decoder\n",
    "            self.decoder_outputs, self.decoder_state, self.final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder=training_decoder,\n",
    "                                                                           impute_finished=True,\n",
    "                                                                           output_time_major=self.time_major,\n",
    "                                                                           maximum_iterations=self.max_target_sequence_length)\n",
    "        \n",
    "            # Inference\n",
    "            start_tokens = tf.tile(tf.constant([self.start_of_sequence_id], dtype=tf.int32), [self.batch_size], name='start_tokens')\n",
    "\n",
    "            # Helper for the inference process.\n",
    "            inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embedding_matrix,\n",
    "                                                                    start_tokens,\n",
    "                                                                    self.end_of_sequence_id)\n",
    "\n",
    "            # Basic decoder\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(cell=self.decoder_cell,\n",
    "                                                            helper=inference_helper,\n",
    "                                                            initial_state=initial_state,\n",
    "                                                            output_layer=output_layer)\n",
    "\n",
    "            # Perform dynamic decoding using the decoder\n",
    "            self.inference_output, _, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                                impute_finished=True,\n",
    "                                                                output_time_major=self.time_major,\n",
    "                                                                maximum_iterations=self.max_target_sequence_length)\n",
    "            \n",
    "            self.training_logits = tf.identity(self.decoder_outputs.rnn_output, 'logits')\n",
    "            self.inference_logits = tf.identity(self.inference_output.sample_id, name='predictions')\n",
    "        \n",
    "     \n",
    "    def _init_optimizer(self):\n",
    "        max_gradient_norm = 5.0\n",
    "        # Create the weights for sequence_loss\n",
    "        self.masks = tf.sequence_mask(self.target_sequence_length, self.max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "        with tf.name_scope(\"optimization\"):\n",
    "            # Loss function\n",
    "            self.train_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                self.training_logits,\n",
    "                self.decoder_targets,\n",
    "                self.masks)\n",
    "            \n",
    "            # Calculate and clip gradients\n",
    "            params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.train_loss, params)\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
    "        \n",
    "            # Optimizer\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            self.train_optimizer = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)\n",
    "    \n",
    "    \n",
    "    def training(self, session, batch_encoder_input, batch_decoder_input, batch_decoder_target):\n",
    "        input_feed = self.preprocessData(batch_encoder_input, batch_decoder_input, batch_decoder_target)\n",
    "        output_feed = [self.train_optimizer, self.train_loss]\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        return outputs[0], outputs[1]\n",
    "    \n",
    "    \n",
    "    def inference(self, session, batch_encoder_input, batch_decoder_input, batch_decoder_target):\n",
    "        input_feed = self.preprocessData(batch_encoder_input, batch_decoder_input, batch_decoder_target)\n",
    "        predict = session.run(self.inference_logits, input_feed)\n",
    "        if self.time_major:\n",
    "            return predict.T\n",
    "        else:\n",
    "            return predict\n",
    "    \n",
    "    \n",
    "    def preprocessData(self, batchX, batchY, batchZ):\n",
    "        input_feed = {}\n",
    "        \n",
    "        if self.time_major:\n",
    "            input_feed[self.encoder_inputs.name] = batchX.T\n",
    "            input_feed[self.decoder_inputs.name] = batchY.T\n",
    "            input_feed[self.decoder_targets.name] = batchZ.T\n",
    "        else:\n",
    "            input_feed[self.encoder_inputs.name] = batchX\n",
    "            input_feed[self.decoder_inputs.name] = batchY\n",
    "            input_feed[self.decoder_targets.name] = batchZ\n",
    "        \n",
    "        pad_targets_lengths = []\n",
    "        for target in batchY:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "            #pad_targets_lengths.append(len(target)-list(target).count(0))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in batchX:\n",
    "            #pad_source_lengths.append(len(source))\n",
    "            pad_source_lengths.append(len(source)-list(source).count(0))\n",
    "            \n",
    "        input_feed[self.source_sequence_length.name] = pad_source_lengths\n",
    "        input_feed[self.target_sequence_length.name] = pad_targets_lengths\n",
    "        \n",
    "        return input_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "num_time_steps=5\n",
    "def create_sample_data():\n",
    "    x = np.random.randint(10, size=(batch_size, num_time_steps), dtype=np.int32)+1\n",
    "    tmp = np.zeros((batch_size, num_time_steps), dtype=np.int32)\n",
    "    for i in range(x.shape[0]):\n",
    "        tmp[i] = x[i][::-1]\n",
    "    \n",
    "    pad = np.zeros((batch_size, 1), dtype=np.int32)\n",
    "    z = np.append(tmp, pad, axis=1)\n",
    "    y = np.append(pad, tmp, axis=1)\n",
    "    #for i in range(x.shape[0]):\n",
    "    #    y[i] = x[i][::-1]\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y, z = create_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch111():\n",
    "    x,y,z = create_sample_data()\n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "def next_batch222():\n",
    "    x,y,z = create_sample_data()\n",
    "    \n",
    "    pad_targets_lengths = []\n",
    "    for target in y:\n",
    "        pad_targets_lengths.append(len(target))\n",
    "    \n",
    "    pad_source_lengths = []\n",
    "    for source in x:\n",
    "        #pad_source_lengths.append(len(source))\n",
    "        pad_source_lengths.append(len(source)-list(source).count(0))\n",
    "            \n",
    "    return {\n",
    "        model.encoder_inputs.name: x.T,\n",
    "        model.decoder_inputs.name: y.T,\n",
    "        model.decoder_targets.name: z.T,\n",
    "        model.source_sequence_length.name: pad_source_lengths,\n",
    "        model.target_sequence_length.name: pad_targets_lengths\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init new model\n"
     ]
    }
   ],
   "source": [
    "args = dict(vocab_size = 11,\n",
    "            embedding_size = 11,\n",
    "            num_units= 256,\n",
    "            num_layers = 4,\n",
    "            out_keep_prob = 0.75,\n",
    "            learning_rate=0.01,\n",
    "            encoder_size=5,\n",
    "            decoder_size=6,\n",
    "            start_of_sequence_id=0,\n",
    "            end_of_sequence_id=0,\n",
    "            pad_of_sequence_id=0,\n",
    "            batch_size=batch_size,\n",
    "            use_attention=True\n",
    "           )\n",
    "model = Seq2Seq(**args)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "batch 50\n",
      "batch 100\n",
      "batch 150\n",
      "batch 200\n",
      "batch 250\n",
      "batch 300\n",
      "batch 350\n",
      "batch 400\n",
      "batch 450\n"
     ]
    }
   ],
   "source": [
    "max_batches = 500\n",
    "batches_in_epoch = 50\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            \n",
    "        x, y, z = next_batch111()\n",
    "        _, l = model.training(sess, x, y, z)\n",
    "        loss_track.append(l)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2ce4ac18>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIub/A/BgXRb8WRVSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b92d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y,z = next_batch111()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = model.inference(sess, x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  5, 10,  6,  2,  0],\n",
       "       [ 6,  7, 10,  4,  2,  0],\n",
       "       [ 4,  7,  2,  1,  7,  0],\n",
       "       [ 7,  9,  7,  8, 10,  0],\n",
       "       [ 5,  5,  7,  7,  8,  0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6, 10,  5,  3],\n",
       "       [ 2,  4, 10,  7,  6],\n",
       "       [ 7,  1,  2,  7,  4],\n",
       "       [10,  8,  7,  9,  7],\n",
       "       [ 8,  7,  7,  5,  5]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
