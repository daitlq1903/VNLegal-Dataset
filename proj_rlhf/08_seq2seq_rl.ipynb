{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DevTools/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(object):\n",
    "    def __init__(self, vocab_size, embedding_size, num_units, num_layers, out_keep_prob, batch_size, encoder_size, decoder_size, start_of_sequence_id, end_of_sequence_id, pad_of_sequence_id, dull_set, learning_rate=0.0001, use_attention=False):\n",
    "        print('Init new model')\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_units = num_units\n",
    "        self.num_layers = num_layers\n",
    "        self.out_keep_prob = out_keep_prob\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.time_major = True\n",
    "        self.use_attention = use_attention\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.counter = tf.Variable(0, name='counter')\n",
    "        \n",
    "        self.encoder_size = encoder_size\n",
    "        self.decoder_size = decoder_size\n",
    "        self.start_of_sequence_id = start_of_sequence_id\n",
    "        self.end_of_sequence_id = end_of_sequence_id\n",
    "        self.pad_of_sequence_id = pad_of_sequence_id\n",
    "        \n",
    "        self.dull_set = dull_set\n",
    "        \n",
    "    def createCell(self, num_units, num_layers):\n",
    "        #return tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "        cells = []\n",
    "        for _ in range(self.num_layers):\n",
    "            cell = tf.contrib.rnn.LSTMCell(self.num_units)  # Or LSTMCell(num_units)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.out_keep_prob)\n",
    "            cells.append(cell)\n",
    "        stacked_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "        return stacked_cell\n",
    "    \n",
    "    \n",
    "    def build(self):\n",
    "        self._init_placeholders()\n",
    "        self._init_embeddings()\n",
    "        #self._init_encoder()\n",
    "        self._init_bidirectional_encoder()\n",
    "        self._init_decoder()\n",
    "        self._init_optimizer()\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        self.encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "        self.decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "        self.decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "        \n",
    "        self.source_sequence_length = tf.placeholder(tf.int32, (None,), name='source_sequence_length')\n",
    "        self.target_sequence_length = tf.placeholder(tf.int32, (None,), name='target_sequence_length')\n",
    "        \n",
    "        self.max_target_sequence_length = tf.reduce_max(self.target_sequence_length, name='max_target_length')\n",
    "        \n",
    "        self.reward = tf.placeholder(tf.float32, name=\"reward\")\n",
    "        \n",
    "        \n",
    "    def _init_embeddings(self):\n",
    "        with tf.variable_scope(\"embedding\") as scope:\n",
    "            # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "            sqrt3 = math.sqrt(3)\n",
    "            initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "            \n",
    "            self.embedding_matrix = tf.get_variable(\n",
    "                                        name=\"embedding_matrix\",\n",
    "                                        shape=[self.vocab_size, self.embedding_size],\n",
    "                                        initializer=initializer,\n",
    "                                        dtype=tf.float32\n",
    "                                    )\n",
    "            \n",
    "            self.embeddings = tf.Variable(tf.random_uniform([self.vocab_size, self.embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "            self.encoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.encoder_inputs)\n",
    "            self.decoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.decoder_inputs)\n",
    "            \n",
    "            #self.encoder_inputs_embedded = tf.contrib.layers.embed_sequence(self.encoder_inputs, self.vocab_size, self.embedding_size)\n",
    "            #self.embedding_matrix = tf.Variable(tf.random_uniform([self.vocab_size, self.embedding_size]))\n",
    "            #self.decoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.decoder_inputs)\n",
    "    \n",
    "    \n",
    "    def _init_encoder(self):\n",
    "        with tf.variable_scope(\"encoder\") as scope:\n",
    "            self.encoder_cell = self.createCell(self.num_units, self.num_layers)\n",
    "            self.encoder_outputs, self.encoder_state = tf.nn.dynamic_rnn(\n",
    "                                                                        cell=self.encoder_cell,\n",
    "                                                                        inputs=self.encoder_inputs_embedded,\n",
    "                                                                        dtype=tf.float32,\n",
    "                                                                        sequence_length=self.source_sequence_length,\n",
    "                                                                        time_major=self.time_major\n",
    "                                                                    )\n",
    "    \n",
    "    \n",
    "    def _init_bidirectional_encoder(self):\n",
    "        with tf.variable_scope(\"bidirectional_encoder\") as scope:\n",
    "            num_bi_layers = int(self.num_layers / 2)\n",
    "            self.encoder_cell_fw = self.createCell(self.num_units, num_bi_layers)\n",
    "            self.encoder_cell_bw = self.createCell(self.num_units, num_bi_layers)\n",
    "            \n",
    "            encoder_outputs, bi_encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                                                cell_fw=self.encoder_cell_fw,\n",
    "                                                                cell_bw=self.encoder_cell_bw,\n",
    "                                                                inputs=self.encoder_inputs_embedded,\n",
    "                                                                dtype=tf.float32,\n",
    "                                                                sequence_length=self.source_sequence_length,\n",
    "                                                                time_major=self.time_major,\n",
    "                                                                swap_memory=True\n",
    "                                                            )\n",
    "            #self.encoder_outputs = tf.concat(outputs, -1)\n",
    "            #self.encoder_state = states\n",
    "            #if num_bi_layers == 1:\n",
    "            #    self.encoder_state = bi_encoder_state\n",
    "            #else:\n",
    "            # alternatively concat forward and backward states\n",
    "            self.encoder_state = []\n",
    "            for layer_id in range(num_bi_layers):\n",
    "                self.encoder_state.append(bi_encoder_state[0][layer_id])  # forward\n",
    "                self.encoder_state.append(bi_encoder_state[1][layer_id])  # backward\n",
    "            self.encoder_state = tuple(self.encoder_state)\n",
    "                \n",
    "            self.encoder_outputs = tf.concat(encoder_outputs, -1)\n",
    "            \n",
    "            \n",
    "    def _init_decoder(self):\n",
    "\n",
    "        output_layer = Dense(self.vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "        \n",
    "        with tf.variable_scope(\"decoder\") as scope:\n",
    "            \n",
    "            if self.use_attention:\n",
    "                #attention_states: [batch_size, max_time, num_units] (not time_major)\n",
    "                if self.time_major:\n",
    "                    attention_states = tf.transpose(self.encoder_outputs, [1, 0, 2])\n",
    "                else:\n",
    "                    attention_states = self.encoder_outputs\n",
    "\n",
    "                # Create an attention mechanism\n",
    "                attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "                                    num_units=self.num_units, memory=attention_states,\n",
    "                                    memory_sequence_length=self.source_sequence_length)\n",
    "                \n",
    "                stacked_cell = self.createCell(self.num_units, self.num_layers)\n",
    "                #attention_cell= tf.contrib.rnn.BasicLSTMCell(self.num_units)\n",
    "                attention_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                                                                    cell=stacked_cell,\n",
    "                                                                    attention_mechanism=attention_mechanism,\n",
    "                                                                    attention_layer_size=self.num_units,  # don't add an additional dense layer.\n",
    "                                                                    output_attention=False)\n",
    "                #self.decoder_cell= GNMTAttentionMultiCell(attention_cell, cells)\n",
    "                \n",
    "                self.decoder_cell = attention_cell\n",
    "\n",
    "                initial_state = self.decoder_cell.zero_state(self.batch_size, tf.float32).clone(cell_state=self.encoder_state)\n",
    "                #initial_state = self.decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
    "            else:\n",
    "                self.decoder_cell = self.createCell(self.num_units, self.num_layers)\n",
    "                initial_state =self.encoder_state\n",
    "            \n",
    "            # Helper for the training process. Used by BasicDecoder to read inputs.\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=self.decoder_inputs_embedded,\n",
    "                                                                sequence_length=self.target_sequence_length,\n",
    "                                                                time_major=self.time_major)\n",
    "\n",
    "\n",
    "            # Basic decoder\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=self.decoder_cell,\n",
    "                                                               helper=training_helper,\n",
    "                                                               initial_state=initial_state,\n",
    "                                                               output_layer=output_layer) \n",
    "\n",
    "            # Perform dynamic decoding using the decoder\n",
    "            self.decoder_outputs, self.decoder_state, self.final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder=training_decoder,\n",
    "                                                                           impute_finished=True,\n",
    "                                                                           output_time_major=self.time_major,\n",
    "                                                                           maximum_iterations=self.max_target_sequence_length)\n",
    "        \n",
    "            # Inference\n",
    "            start_tokens = tf.tile(tf.constant([self.start_of_sequence_id], dtype=tf.int32), [self.batch_size], name='start_tokens')\n",
    "\n",
    "            # Helper for the inference process.\n",
    "            inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embedding_matrix,\n",
    "                                                                    start_tokens,\n",
    "                                                                    self.end_of_sequence_id)\n",
    "\n",
    "            # Basic decoder\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(cell=self.decoder_cell,\n",
    "                                                            helper=inference_helper,\n",
    "                                                            initial_state=initial_state,\n",
    "                                                            output_layer=output_layer)\n",
    "\n",
    "            # Perform dynamic decoding using the decoder\n",
    "            self.inference_output, _, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                                impute_finished=True,\n",
    "                                                                output_time_major=self.time_major,\n",
    "                                                                maximum_iterations=self.max_target_sequence_length)\n",
    "            \n",
    "            self.training_logits = tf.identity(self.decoder_outputs.rnn_output, 'logits')\n",
    "            self.inference_logits = tf.identity(self.inference_output.sample_id, name='predictions')\n",
    "        \n",
    "     \n",
    "    def _init_optimizer(self):\n",
    "        max_gradient_norm = 5.0\n",
    "        # Create the weights for sequence_loss\n",
    "        self.masks = tf.sequence_mask(self.target_sequence_length, self.max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "        with tf.name_scope(\"optimization\"):\n",
    "            # Loss function\n",
    "            self.train_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                self.training_logits,\n",
    "                self.decoder_targets,\n",
    "                self.masks)\n",
    "\n",
    "            # Calculate and clip gradients\n",
    "            params = tf.trainable_variables()\n",
    "\n",
    "            # reinforcement learning\n",
    "            #self.adjusted_losses = tf.multiply(self.train_loss, self.reward)\n",
    "            #gradients = tf.gradients(self.adjusted_losses, params)\n",
    "\n",
    "            # seq2seq\n",
    "            gradients = tf.gradients(self.train_loss, params)\n",
    "\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
    "\n",
    "            # Optimizer\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            self.train_optimizer = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)\n",
    "    \n",
    "    \n",
    "    def training(self, session, input_feed, reward, forward_only=False):\n",
    "        input_feed[self.reward.name] = reward\n",
    "        if forward_only:\n",
    "            output_feed = [self.encoder_state, self.train_loss, self.training_logits]\n",
    "            outputs = session.run(output_feed, input_feed)\n",
    "            return outputs[0], outputs[1], outputs[2]\n",
    "        else:\n",
    "            output_feed = [self.train_optimizer, self.train_loss]\n",
    "            outputs = session.run(output_feed, input_feed)\n",
    "            return outputs[0], outputs[1]\n",
    "    \n",
    "    \n",
    "    def training_rl(self, session, input_feed):\n",
    "        list_encoder_states = []\n",
    "        episode = 0\n",
    "        rewards = []\n",
    "        input_feed_tmp = input_feed\n",
    "        while True:\n",
    "            encoder_states, step_loss, output_logits = self.training(session, input_feed_tmp, reward=1, forward_only=True)\n",
    "\n",
    "            encoder_states_h = encoder_states[num_layers-1].h\n",
    "            list_encoder_states.append(encoder_states_h)\n",
    "#             if self.time_major:\n",
    "#                 encoder_states = tf.transpose(encoder_states, [1, 0, 2])\n",
    "#             else:\n",
    "#                 encoder_states = encoder_states\n",
    "\n",
    "            resp_tokens = self.logits2tokens(output_logits)\n",
    "\n",
    "            if episode > 9:\n",
    "                break\n",
    "                \n",
    "            # --------[Reward]--------\n",
    "            # r1: Ease of answering\n",
    "            r1 = [self.logProb(session, [d for _ in resp_tokens], resp_tokens) for d in self.dull_set]\n",
    "            r1 = -np.mean(r1) if r1 else 0\n",
    "\n",
    "            # r2: Information Flow\n",
    "            r2_list = []\n",
    "            if len(list_encoder_states) < 4:\n",
    "                r2 = 0\n",
    "            else:\n",
    "                batch_vec_a, batch_vec_b = list_encoder_states[-3], list_encoder_states[-1]\n",
    "                for i, (vec_a, vec_b) in enumerate(zip(batch_vec_a, batch_vec_b)):\n",
    "                    rr2 = sum(vec_a * vec_b) / sum(abs(vec_a) * abs(vec_b))\n",
    "                    # print(\"vec_a*vec_b: %s\" %sum(vec_a*vec_b))\n",
    "                    # print(\"r2: %s\" %r2)\n",
    "                    if (rr2 < 0):\n",
    "                        print(\"rr2: \", rr2)\n",
    "                        print(\"vec_a: \", vec_a)\n",
    "                        print(\"vec_b: \", vec_b)\n",
    "                        rr2 = -rr2\n",
    "                    else:\n",
    "                        rr2 = -np.log(rr2)\n",
    "                    r2_list.append(rr2)\n",
    "                r2 = sum(r2_list) / len(r2_list)\n",
    "            \n",
    "            # r3: Semantic Coherence\n",
    "            r3 = 0\n",
    "            \n",
    "            # Episode total reward\n",
    "            print(\"r1: %s, r2: %s, r3: %s\" % (r1, r2, r3))\n",
    "            R = 0.25 * r1 + 0.25 * r2 + 0.5 * r3\n",
    "            rewards.append(R)\n",
    "            \n",
    "            # prepare for next dialogue\n",
    "            new_questions = resp_tokens\n",
    "            new_answers = []\n",
    "            for _ in range(len(new_questions)):\n",
    "                new_answers.append([])\n",
    "            input_feed_tmp = self.get_batch(new_questions, new_answers)\n",
    "            \n",
    "            episode += 1\n",
    "        \n",
    "        reward = [np.mean(rewards)]\n",
    "        train_optimizer, train_loss = self.training(session, input_feed, reward=reward, forward_only=False)\n",
    "        return train_optimizer, train_loss\n",
    "    \n",
    "        \n",
    "    def test(self, session, questions, answers):\n",
    "        input_feed = self.get_batch(questions, answers)\n",
    "        predict = session.run(self.inference_logits, input_feed)\n",
    "        if self.time_major:\n",
    "            return input_feed[self.encoder_inputs.name].T, input_feed[self.decoder_targets.name].T, predict.T\n",
    "        else:\n",
    "            return input_feed[self.encoder_inputs.name], input_feed[self.decoder_targets.name], predict\n",
    "    \n",
    "    \n",
    "#     def inference(self, session, batch_encoder_input, batch_decoder_input, batch_decoder_target):\n",
    "#         input_feed = self.preprocessData(batch_encoder_input, batch_decoder_input, batch_decoder_target)\n",
    "#         predict = session.run(self.inference_logits, input_feed)\n",
    "#         if self.time_major:\n",
    "#             return predict.T\n",
    "#         else:\n",
    "#             return predict\n",
    "    \n",
    "    \n",
    "    def get_batch(self, questions, answers):\n",
    "        \n",
    "        encoder_inputs, decoder_inputs, decoder_targets = [], [], []\n",
    "        for _ in range(self.batch_size):\n",
    "            idx = random.randrange(len(questions))\n",
    "            encoder_input = questions[idx]\n",
    "            decoder_input = answers[idx]\n",
    "            decoder_target = answers[idx]\n",
    "\n",
    "            # Encoder inputs are padded and then reversed.\n",
    "            encoder_pad = [self.pad_of_sequence_id] * (self.encoder_size - len(encoder_input))\n",
    "            encoder_inputs.append(list(encoder_input + encoder_pad))\n",
    "\n",
    "            # Decoder inputs get an extra \"GO\" symbol, and are padded then.\n",
    "            decoder_pad_size = self.decoder_size - len(decoder_input) - 1\n",
    "            decoder_inputs.append([self.start_of_sequence_id] + decoder_input + [self.pad_of_sequence_id] * decoder_pad_size)\n",
    "            decoder_targets.append(decoder_target + [self.end_of_sequence_id] + [self.pad_of_sequence_id] * decoder_pad_size)\n",
    "    \n",
    "        pad_source_lengths = []\n",
    "        for source in encoder_inputs:\n",
    "            #pad_source_lengths.append(len(source))\n",
    "            pad_source_lengths.append(len(source)-list(source).count(0))\n",
    "            \n",
    "        pad_targets_lengths = []\n",
    "        for target in decoder_targets:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "            #pad_targets_lengths.append(len(target)-list(target).count(0))\n",
    "        \n",
    "        if self.time_major:\n",
    "            a = encoder_inputs\n",
    "            encoder_inputs = np.array(encoder_inputs).T\n",
    "            decoder_inputs = np.array(decoder_inputs).T\n",
    "            decoder_targets = np.array(decoder_targets).T\n",
    "        \n",
    "        #print(encoder_inputs)\n",
    "        if encoder_inputs.shape == (32,):\n",
    "            print(questions)\n",
    "            print(np.array(a).shape)\n",
    "            \n",
    "        return {\n",
    "            self.encoder_inputs.name: encoder_inputs,\n",
    "            self.decoder_inputs.name: decoder_inputs,\n",
    "            self.decoder_targets.name: decoder_targets,\n",
    "            self.source_sequence_length.name: pad_source_lengths,\n",
    "            self.target_sequence_length.name: pad_targets_lengths\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def logits2tokens(self, output_logits):\n",
    "        logits = np.argmax(output_logits, -1)\n",
    "        if self.time_major:\n",
    "            logits = logits.T\n",
    "        tokens = []\n",
    "        for i in logits:\n",
    "            token = list(i)\n",
    "            if self.end_of_sequence_id in token:\n",
    "                EOS_TOKEN = token.index(self.end_of_sequence_id)\n",
    "                token = token[:EOS_TOKEN]\n",
    "            elif self.pad_of_sequence_id in token:\n",
    "                EOS_TOKEN = token.index(self.pad_of_sequence_id)\n",
    "                token = token[:EOS_TOKEN]\n",
    "            tokens.append(token)\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "    def logits2tokens1(self, logits):\n",
    "        tokens = np.argmax(logits, -1)\n",
    "        if self.time_major:\n",
    "            tokens = tokens.T\n",
    "        \n",
    "        l_tokens = [list(i) for i in tokens]\n",
    "        \n",
    "        if self.end_of_sequence_id in l_tokens:\n",
    "            eos = tokens.index(self.end_of_sequence_id)\n",
    "        \n",
    "        tokens = tokens[:eos]\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "    # the conditional likelyhood: log(P(a|b)\n",
    "    def logProb(self, session, tokens_a, tokens_b):\n",
    "        def softmax(x):\n",
    "            return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        \n",
    "        input_feed = self.get_batch(tokens_b, tokens_a)\n",
    "        \n",
    "        _, _, output_logits = self.training(session, input_feed, reward=1, forward_only=True)\n",
    "        \n",
    "#         p = log(P(b|a)) / N\n",
    "#         p = 1\n",
    "#         for t, logit in zip(tokens_b, output_logits):\n",
    "#             p *= softmax(logit[0])[t]\n",
    "#         p = np.log(p) / len(tokens_b)\n",
    "#         return p\n",
    "        \n",
    "        sum_p = []\n",
    "        for i, (tokens, logits) in enumerate(zip(tokens_a, output_logits)):\n",
    "            #print(\"tokens: %s, index: %d\" % (tokens, i))\n",
    "\n",
    "            p = 1\n",
    "            for t, logit in zip(tokens, logits):\n",
    "                # print(\"logProb: logit: %s\" %logit)\n",
    "                norm = softmax(logit)[t]\n",
    "                # print (\"t: %s, norm: %s\" %(t, norm))\n",
    "                p *= norm\n",
    "            if p < 1e-100:\n",
    "                # print (\"p: \", p)\n",
    "                p = 1e-100\n",
    "            p = np.log(p) / len(tokens)\n",
    "            #print (\"logProb: p: %s\" % (p))\n",
    "            sum_p.append(p)\n",
    "        logP = np.sum(sum_p) / len(sum_p)\n",
    "        return logP\n",
    "    \n",
    "\n",
    "    def training1(self, session, questions, answers):\n",
    "        input_feed = self.get_batch(questions, answers)\n",
    "        output_feed = [self.train_optimizer, self.train_loss]\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        return outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = 'data/cornell'\n",
    "with open(DATA+'/metadata.npy', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "    questions = np.load(DATA+'/questions.npy')\n",
    "    answers = np.load(DATA+'/answers.npy')\n",
    "    dull_set = np.load(DATA+'/dull_set.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153455\n",
      "153455\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(sequence, lookup, separator=''): # 0 used for padding, is ignored\n",
    "    return separator.join([ lookup[element] for element in sequence if element ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['vocab_to_int']['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "#batch_train_gen = rand_batch_gen(trainX, trainY, trainZ, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "\n",
    "args = dict(vocab_size = len(metadata['vocab_to_int']),\n",
    "            embedding_size = 512,\n",
    "            num_units= 512,\n",
    "            num_layers = 4,\n",
    "            out_keep_prob = 0.75,\n",
    "            learning_rate=0.01,\n",
    "            encoder_size=25,\n",
    "            decoder_size=26,\n",
    "            start_of_sequence_id=metadata['vocab_to_int']['<GO>'],\n",
    "            end_of_sequence_id=metadata['vocab_to_int']['<EOS>'],\n",
    "            pad_of_sequence_id=metadata['vocab_to_int']['<PAD>'],\n",
    "            dull_set=dull_set,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            use_attention=True\n",
    "           )\n",
    "model = Seq2Seq(**args)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\"save\", \"model.ckpt\")\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(\"save\")\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    model.saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batches = 20\n",
    "batches_in_epoch = 10\n",
    "loss_track = []\n",
    "steps_per_checkpoint = 10\n",
    "\n",
    "checkpoint_path = os.path.join(\"save\", \"model.ckpt\")\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(\"save\")\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    model.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "try:\n",
    "    for batch in range(1, 1 + 1):\n",
    "        if batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "        input_feed = model.get_batch(questions, answers)\n",
    "        #_, l = model.training(sess, input_feed, forward_only=False)\n",
    "        #loss_track.append(l)\n",
    "        \n",
    "        #if batch % steps_per_checkpoint == 0:\n",
    "        #    model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "        \n",
    "        \n",
    "        _, l = model.training_rl(sess, input_feed)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_, output_, predict_  = model.test(sess, questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replies = []\n",
    "for ii, oi, pi in zip(input_, output_, predict_):\n",
    "    ip = decode(sequence=ii, lookup=metadata['int_to_vocab'], separator=' ')\n",
    "    op = decode(sequence=oi, lookup=metadata['int_to_vocab'], separator=' ').split(' ')\n",
    "    pp = decode(sequence=pi, lookup=metadata['int_to_vocab'], separator=' ').split(' ')\n",
    "    #if pp.count('UNK') == 0:\n",
    "    if pp not in replies:\n",
    "        print('Q: {0};\\nA: {1}\\nP: {2}\\n'.format(ip, ' '.join(op), ' '.join(pp)))\n",
    "        replies.append(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = model.get_batch(questions,answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_states, step_loss, output_logits = model.training(sess, fd, reward=1, forward_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = np.argmax(output_logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = logits.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i in logits:\n",
    "    token = list(i)\n",
    "    if 15 in token:\n",
    "        eos = token.index(1)\n",
    "        token = token[:eos]\n",
    "    tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tokens[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_logits1 = model.logits2tokens(output_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_logits1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resp_tokens=output_logits1\n",
    "\n",
    "feed_data = {1: [(resp_tokens, [])]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions, answers = [], []\n",
    "for batch_i in range(32):\n",
    "    encoder_input_a, decoder_input = feed_data[1][0]\n",
    "    encoder_input = encoder_input_a[batch_i]\n",
    "    questions.append(encoder_input)\n",
    "    answers.append(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_questions = resp_tokens\n",
    "new_answers = []\n",
    "for _ in range(len(new_questions)):\n",
    "    new_answers.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.get_batch(new_questions, new_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy = [dull_set[0] for _ in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_feed = model.get_batch(tokens, dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, output_logits = model.training(sess, input_feed, forward_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_logits = np.transpose(output_logits, [1, 0, 2])\n",
    "print(output_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "p = 1\n",
    "for t, logit in zip(dummy, output_logits):\n",
    "    p *= softmax(logit[0])[t]\n",
    "    #print(softmax(logit[0])[t])\n",
    "    #print(p)\n",
    "    #print(\"---------------\")\n",
    "#p = np.log(p) / len(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.log(p)/len(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_p = []\n",
    "for i, (tokens, logits) in enumerate(zip(dummy, output_logits)):\n",
    "    print(\"tokens: %s, index: %d\" % (tokens, i))\n",
    "    \n",
    "    p = 1\n",
    "    for t, logit in zip(tokens, logits):\n",
    "        # print(\"logProb: logit: %s\" %logit)\n",
    "        norm = softmax(logit)[t]\n",
    "        # print (\"t: %s, norm: %s\" %(t, norm))\n",
    "        p *= norm\n",
    "    if p < 1e-100:\n",
    "        # print (\"p: \", p)\n",
    "        p = 1e-100\n",
    "    p = np.log(p) / len(tokens)\n",
    "    print (\"logProb: p: %s\" % (p))\n",
    "    sum_p.append(p)\n",
    "re = np.sum(sum_p) / len(sum_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p = log(P(b|a)) / N\n",
    "p = 1\n",
    "for t, logit in zip(tokens_b, output_logits):\n",
    "    p *= softmax(logit[0])[t]\n",
    "p = log(p) / len(tokens_b)\n",
    "return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = logits\n",
    "a = dummy\n",
    "encoder_inputs, decoder_inputs, decoder_targets = [], [], []\n",
    "for _ in range(5):\n",
    "    idx = random.randrange(len(q))\n",
    "    encoder_input = q[idx]\n",
    "    decoder_input = a[idx]\n",
    "    decoder_target = a[idx]\n",
    "\n",
    "    # Encoder inputs are padded and then reversed.\n",
    "    encoder_pad = [0] * (25 - len(encoder_input))\n",
    "    encoder_inputs.append(list(encoder_input + encoder_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input=q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata['int_to_vocab'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_pad = [0] * (25 - len(encoder_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ep_encoder_inputs =[]\n",
    "for i in range(10):\n",
    "    fd = model.get_batch(questions, answers)\n",
    "    ep_encoder_inputs.append(fd[model.encoder_inputs.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_trans = np.transpose(ep_encoder_inputs, axes=(1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ep_encoder_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_type(sequence, type=0):\n",
    "    tokens = []\n",
    "    resps = []\n",
    "    if type == 0:\n",
    "        tokens = [i for i in [t for t in reversed(sequence)] if i.sum() != 0]\n",
    "    elif type == 1:\n",
    "    #print (\"remove_type type=1 tokens: %s\" %sequence)\n",
    "\n",
    "        for seq in sequence:\n",
    "             #print(\"seq: %s\" %seq)\n",
    "             token = []\n",
    "             for t in seq:\n",
    "                 #print(\"seq_t: %s\" %t)\n",
    "                 # t = list(t)\n",
    "                 # print(\"list(t): %s\" %t)\n",
    "                 # t = np.array(t)\n",
    "                 # print(\"array(t): %s\" %t)\n",
    "                 token.append(int(np.argmax(t, axis=0)))\n",
    "             tokens.append(token)\n",
    "\n",
    "    #tokens = [i for i in [int(np.argmax(t, axis=1)) for t in [seq for seq in sequence]]]\n",
    "    #tokens = [i for i in [int(t.index(max(t))) for t in [seq for seq in sequence]]]\n",
    "    else:\n",
    "        print (\"type only 0(encoder_inputs) or 1(decoder_outputs)\")\n",
    "    #print(\"remove_type tokens: %s\" %tokens)\n",
    "    tokens_t = []\n",
    "    for col in range(len(tokens[0])):\n",
    "        tokens_t.append([tokens[row][col] for row in range(len(tokens))])\n",
    "\n",
    "    for seq in tokens_t:\n",
    "        if metadata['vocab_to_int']['<PAD>'] in seq:\n",
    "            resps.append(seq[:seq.index(0)][:6])\n",
    "        else:\n",
    "            resps.append(seq[:6])\n",
    "    return resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sample_data(batch_size, num_time_steps):\n",
    "    x, y = [], []\n",
    "    for _ in range(batch_size):\n",
    "        x_ = np.random.randint(10, size=num_time_steps) + 1\n",
    "        y_ = x_[::-1]\n",
    "        x.append(list(x_))\n",
    "        y.append(list(y_))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = create_sample_data(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init new model\n"
     ]
    }
   ],
   "source": [
    "args = dict(vocab_size = 11,\n",
    "            embedding_size = 11,\n",
    "            num_units= 512,\n",
    "            num_layers = 4,\n",
    "            out_keep_prob = 0.75,\n",
    "            learning_rate=0.01,\n",
    "            encoder_size=5,\n",
    "            decoder_size=6,\n",
    "            start_of_sequence_id=0,\n",
    "            end_of_sequence_id=0,\n",
    "            pad_of_sequence_id=0,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            dull_set=[],\n",
    "            use_attention=True\n",
    "           )\n",
    "model = Seq2Seq(**args)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 50\n",
      "batch 100\n",
      "batch 150\n",
      "batch 200\n",
      "batch 250\n",
      "batch 300\n",
      "batch 350\n",
      "batch 400\n",
      "batch 450\n",
      "batch 500\n"
     ]
    }
   ],
   "source": [
    "max_batches = 500\n",
    "batches_in_epoch = 50\n",
    "loss_track = []\n",
    "steps_per_checkpoint = 10\n",
    "\n",
    "checkpoint_path = os.path.join(\"save\", \"model_test.ckpt\")\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(\"save\")\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    model.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "try:\n",
    "    for batch in range(1, max_batches + 1):\n",
    "        if batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "        input_feed = model.get_batch(x, y)\n",
    "        _, l = model.training(sess, input_feed, reward=1)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch % steps_per_checkpoint == 0:\n",
    "            model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')\n",
    "\n",
    "\n",
    "#saver.save(sess, os.path.join('save', 'model_noatt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3bbdb3c8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a33f17ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i, o, p = model.test(sess, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  8,  5,  5,  9],\n",
       "       [10,  4,  6,  3,  3],\n",
       "       [ 7,  5,  1,  3, 10],\n",
       "       [ 8,  6,  5,  7,  2],\n",
       "       [ 7,  1,  4,  9,  3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  5,  5,  8,  3,  0],\n",
       "       [ 3,  3,  6,  4, 10,  0],\n",
       "       [10,  3,  1,  5,  7,  0],\n",
       "       [ 2,  7,  5,  6,  8,  0],\n",
       "       [ 3,  9,  4,  1,  7,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  5,  5,  8,  3,  0],\n",
       "       [ 3,  3,  6,  4, 10,  0],\n",
       "       [10,  3,  1,  5,  7,  0],\n",
       "       [ 2,  7,  5,  6,  8,  0],\n",
       "       [ 3,  9,  4,  7,  7,  0]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = model.get_batch(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = sess.run([model.training_logits, model.inference_logits], fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = np.argmax(a, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1.T[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.T[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = remove_type(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = [2, 3, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
